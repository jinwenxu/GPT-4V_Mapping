{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "! pip install gradio_client"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WSTIHQ64Vc75",
        "outputId": "0edb6bef-867d-43fa-a296-5b2726f2f46d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting gradio_client\n",
            "  Downloading gradio_client-0.10.1-py3-none-any.whl (307 kB)\n",
            "\u001b[?25l     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/307.9 kB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K     \u001b[91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[91m╸\u001b[0m \u001b[32m307.2/307.9 kB\u001b[0m \u001b[31m10.8 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\r\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m307.9/307.9 kB\u001b[0m \u001b[31m8.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from gradio_client) (2023.6.0)\n",
            "Collecting httpx>=0.24.1 (from gradio_client)\n",
            "  Downloading httpx-0.27.0-py3-none-any.whl (75 kB)\n",
            "\u001b[?25l     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/75.6 kB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m75.6/75.6 kB\u001b[0m \u001b[31m11.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: huggingface-hub>=0.19.3 in /usr/local/lib/python3.10/dist-packages (from gradio_client) (0.20.3)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.10/dist-packages (from gradio_client) (23.2)\n",
            "Requirement already satisfied: typing-extensions~=4.0 in /usr/local/lib/python3.10/dist-packages (from gradio_client) (4.9.0)\n",
            "Collecting websockets<12.0,>=10.0 (from gradio_client)\n",
            "  Downloading websockets-11.0.3-cp310-cp310-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl (129 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m129.9/129.9 kB\u001b[0m \u001b[31m19.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: anyio in /usr/local/lib/python3.10/dist-packages (from httpx>=0.24.1->gradio_client) (3.7.1)\n",
            "Requirement already satisfied: certifi in /usr/local/lib/python3.10/dist-packages (from httpx>=0.24.1->gradio_client) (2024.2.2)\n",
            "Collecting httpcore==1.* (from httpx>=0.24.1->gradio_client)\n",
            "  Downloading httpcore-1.0.4-py3-none-any.whl (77 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m77.8/77.8 kB\u001b[0m \u001b[31m12.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: idna in /usr/local/lib/python3.10/dist-packages (from httpx>=0.24.1->gradio_client) (3.6)\n",
            "Requirement already satisfied: sniffio in /usr/local/lib/python3.10/dist-packages (from httpx>=0.24.1->gradio_client) (1.3.0)\n",
            "Collecting h11<0.15,>=0.13 (from httpcore==1.*->httpx>=0.24.1->gradio_client)\n",
            "  Downloading h11-0.14.0-py3-none-any.whl (58 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m58.3/58.3 kB\u001b[0m \u001b[31m8.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from huggingface-hub>=0.19.3->gradio_client) (3.13.1)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from huggingface-hub>=0.19.3->gradio_client) (2.31.0)\n",
            "Requirement already satisfied: tqdm>=4.42.1 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub>=0.19.3->gradio_client) (4.66.2)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub>=0.19.3->gradio_client) (6.0.1)\n",
            "Requirement already satisfied: exceptiongroup in /usr/local/lib/python3.10/dist-packages (from anyio->httpx>=0.24.1->gradio_client) (1.2.0)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->huggingface-hub>=0.19.3->gradio_client) (3.3.2)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->huggingface-hub>=0.19.3->gradio_client) (2.0.7)\n",
            "Installing collected packages: websockets, h11, httpcore, httpx, gradio_client\n",
            "Successfully installed gradio_client-0.10.1 h11-0.14.0 httpcore-1.0.4 httpx-0.27.0 websockets-11.0.3\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from subprocess import getoutput\n",
        "from IPython.display import HTML\n",
        "!apt-get install xattr > /dev/null\n",
        "\n",
        "def get_shareable_link(file_path):\n",
        "  fid = getoutput(\"xattr -p 'user.drive.id' \" + \"'\" + file_path + \"'\")\n",
        "  # make a link and display it\n",
        "  return fid"
      ],
      "metadata": {
        "id": "QvjIDgGbtkkS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# mount to Google Drive to save prompt outputs\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8gwcfCnzuAbP",
        "outputId": "bda20540-4bf9-4746-f7bc-f092bd535c3f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import glob\n",
        "output_files = glob.glob(\"/content/drive/MyDrive/GPT4Mapping_test/output/Prompt_1.2*Sphinx.txt\")\n"
      ],
      "metadata": {
        "id": "D2g498kW-R0e"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "len(output_files)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "r8Qrnkzx-S2x",
        "outputId": "e259b885-6e7d-48f7-e73e-7ccfde7bf654"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "100"
            ]
          },
          "metadata": {},
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pLedAzHBVcN1",
        "outputId": "23e403d4-3bd0-433d-c4b7-d459c099386b"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/huggingface_hub/utils/_token.py:88: UserWarning: \n",
            "The secret `HF_TOKEN` does not exist in your Colab secrets.\n",
            "To authenticate with the Hugging Face Hub, create a token in your settings tab (https://huggingface.co/settings/tokens), set it as secret in your Google Colab and restart your session.\n",
            "You will be able to reuse this secret in all of your notebooks.\n",
            "Please note that authentication is recommended but still optional to access public models or datasets.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Loaded as API: http://llama-adapter.opengvlab.com/ ✔\n",
            "Processed: pop_batch_dot_05.jpeg\n",
            "Loaded as API: http://llama-adapter.opengvlab.com/ ✔\n",
            "An error occurred while processing pop_batch_dot_39.jpeg: no close frame received or sent\n",
            "Loaded as API: http://llama-adapter.opengvlab.com/ ✔\n",
            "Processed: pop_batch_dot_39.jpeg\n",
            "Loaded as API: http://llama-adapter.opengvlab.com/ ✔\n",
            "Processed: pop_batch_dot_40.jpeg\n",
            "Loaded as API: http://llama-adapter.opengvlab.com/ ✔\n",
            "Processed: pop_batch_dot_45.jpeg\n",
            "Loaded as API: http://llama-adapter.opengvlab.com/ ✔\n",
            "An error occurred while processing pop_batch_dot_47.jpeg: received 1000 (OK); then sent 1000 (OK)\n",
            "Loaded as API: http://llama-adapter.opengvlab.com/ ✔\n",
            "Processed: pop_batch_dot_47.jpeg\n",
            "Loaded as API: http://llama-adapter.opengvlab.com/ ✔\n",
            "Processed: pop_batch_dot_48.jpeg\n",
            "Loaded as API: http://llama-adapter.opengvlab.com/ ✔\n",
            "Processed: pop_batch_dot_51.jpeg\n",
            "Loaded as API: http://llama-adapter.opengvlab.com/ ✔\n",
            "Processed: pop_batch_dot_54.jpeg\n",
            "Loaded as API: http://llama-adapter.opengvlab.com/ ✔\n",
            "Processed: pop_batch_gcmap_01.jpeg\n",
            "Loaded as API: http://llama-adapter.opengvlab.com/ ✔\n",
            "Processed: pop_batch_gcmap_05.jpeg\n",
            "Loaded as API: http://llama-adapter.opengvlab.com/ ✔\n",
            "Processed: pop_batch_gcmap_12.jpeg\n",
            "Loaded as API: http://llama-adapter.opengvlab.com/ ✔\n",
            "Processed: pop_batch_gcmap_13.jpeg\n",
            "Loaded as API: http://llama-adapter.opengvlab.com/ ✔\n",
            "Processed: pop_batch_gcmap_17.jpeg\n",
            "Loaded as API: http://llama-adapter.opengvlab.com/ ✔\n",
            "Processed: pop_batch_gcmap_18.jpeg\n",
            "Loaded as API: http://llama-adapter.opengvlab.com/ ✔\n",
            "Processed: pop_batch_gcmap_20.jpeg\n",
            "Loaded as API: http://llama-adapter.opengvlab.com/ ✔\n",
            "Processed: pop_batch_gcmap_21.jpeg\n",
            "Loaded as API: http://llama-adapter.opengvlab.com/ ✔\n",
            "Processed: pop_batch_gcmap_22.jpeg\n",
            "Loaded as API: http://llama-adapter.opengvlab.com/ ✔\n",
            "Processed: pop_batch_gcmap_24.jpeg\n",
            "Loaded as API: http://llama-adapter.opengvlab.com/ ✔\n",
            "Processed: pop_batch_gcmap_28.jpeg\n",
            "Loaded as API: http://llama-adapter.opengvlab.com/ ✔\n",
            "An error occurred while processing pop_batch_gcmap_29.jpeg: received 1000 (OK); then sent 1000 (OK)\n",
            "Loaded as API: http://llama-adapter.opengvlab.com/ ✔\n",
            "Processed: pop_batch_gcmap_29.jpeg\n",
            "Loaded as API: http://llama-adapter.opengvlab.com/ ✔\n",
            "Processed: pop_batch_gcmap_37.jpeg\n",
            "Loaded as API: http://llama-adapter.opengvlab.com/ ✔\n",
            "Processed: pop_batch_gcmap_39.jpeg\n",
            "Loaded as API: http://llama-adapter.opengvlab.com/ ✔\n",
            "Processed: pop_batch_gcmap_40.jpeg\n",
            "Loaded as API: http://llama-adapter.opengvlab.com/ ✔\n",
            "Processed: pop_batch_gcmap_45.jpeg\n",
            "Loaded as API: http://llama-adapter.opengvlab.com/ ✔\n",
            "Processed: pop_batch_gcmap_47.jpeg\n",
            "Loaded as API: http://llama-adapter.opengvlab.com/ ✔\n",
            "Processed: pop_batch_gcmap_48.jpeg\n",
            "Loaded as API: http://llama-adapter.opengvlab.com/ ✔\n",
            "Processed: pop_batch_gcmap_51.jpeg\n",
            "Loaded as API: http://llama-adapter.opengvlab.com/ ✔\n",
            "Processed: pop_batch_gcmap_54.jpeg\n",
            "Loaded as API: http://llama-adapter.opengvlab.com/ ✔\n",
            "An error occurred while processing pop_batch_psmap_01.jpeg: received 1000 (OK); then sent 1000 (OK)\n",
            "Loaded as API: http://llama-adapter.opengvlab.com/ ✔\n",
            "Processed: pop_batch_psmap_01.jpeg\n",
            "Loaded as API: http://llama-adapter.opengvlab.com/ ✔\n",
            "An error occurred while processing pop_batch_psmap_05.jpeg: received 1000 (OK); then sent 1000 (OK)\n",
            "Loaded as API: http://llama-adapter.opengvlab.com/ ✔\n",
            "Processed: pop_batch_psmap_05.jpeg\n",
            "Loaded as API: http://llama-adapter.opengvlab.com/ ✔\n",
            "Processed: pop_batch_psmap_12.jpeg\n",
            "Loaded as API: http://llama-adapter.opengvlab.com/ ✔\n",
            "Processed: pop_batch_psmap_13.jpeg\n",
            "Loaded as API: http://llama-adapter.opengvlab.com/ ✔\n",
            "Processed: pop_batch_psmap_17.jpeg\n",
            "Loaded as API: http://llama-adapter.opengvlab.com/ ✔\n",
            "Processed: pop_batch_psmap_18.jpeg\n",
            "Loaded as API: http://llama-adapter.opengvlab.com/ ✔\n",
            "Processed: pop_batch_psmap_20.jpeg\n",
            "Loaded as API: http://llama-adapter.opengvlab.com/ ✔\n",
            "An error occurred while processing pop_batch_psmap_21.jpeg: received 1000 (OK); then sent 1000 (OK)\n",
            "Loaded as API: http://llama-adapter.opengvlab.com/ ✔\n",
            "Processed: pop_batch_psmap_21.jpeg\n",
            "Loaded as API: http://llama-adapter.opengvlab.com/ ✔\n",
            "Processed: pop_batch_psmap_22.jpeg\n",
            "Loaded as API: http://llama-adapter.opengvlab.com/ ✔\n",
            "An error occurred while processing pop_batch_psmap_24.jpeg: received 1000 (OK); then sent 1000 (OK)\n",
            "Loaded as API: http://llama-adapter.opengvlab.com/ ✔\n",
            "Processed: pop_batch_psmap_24.jpeg\n",
            "Loaded as API: http://llama-adapter.opengvlab.com/ ✔\n",
            "Processed: pop_batch_psmap_28.jpeg\n",
            "Loaded as API: http://llama-adapter.opengvlab.com/ ✔\n",
            "Processed: pop_batch_psmap_29.jpeg\n",
            "Loaded as API: http://llama-adapter.opengvlab.com/ ✔\n",
            "Processed: pop_batch_psmap_37.jpeg\n",
            "Loaded as API: http://llama-adapter.opengvlab.com/ ✔\n",
            "Processed: pop_batch_psmap_39.jpeg\n",
            "Loaded as API: http://llama-adapter.opengvlab.com/ ✔\n",
            "Processed: pop_batch_psmap_40.jpeg\n",
            "Loaded as API: http://llama-adapter.opengvlab.com/ ✔\n",
            "Processed: pop_batch_psmap_45.jpeg\n",
            "Loaded as API: http://llama-adapter.opengvlab.com/ ✔\n",
            "Processed: pop_batch_psmap_47.jpeg\n",
            "Loaded as API: http://llama-adapter.opengvlab.com/ ✔\n",
            "Processed: pop_batch_psmap_48.jpeg\n",
            "Loaded as API: http://llama-adapter.opengvlab.com/ ✔\n",
            "An error occurred while processing pop_batch_psmap_51.jpeg: received 1000 (OK); then sent 1000 (OK)\n",
            "Loaded as API: http://llama-adapter.opengvlab.com/ ✔\n",
            "Processed: pop_batch_psmap_51.jpeg\n",
            "Loaded as API: http://llama-adapter.opengvlab.com/ ✔\n",
            "An error occurred while processing pop_batch_psmap_54.jpeg: received 1000 (OK); then sent 1000 (OK)\n",
            "Loaded as API: http://llama-adapter.opengvlab.com/ ✔\n",
            "Processed: pop_batch_psmap_54.jpeg\n"
          ]
        }
      ],
      "source": [
        "from gradio_client import Client\n",
        "import os\n",
        "import time\n",
        "from pathlib import Path\n",
        "import glob\n",
        "max_retries = 2\n",
        "\n",
        "output_files = glob.glob(\"/content/drive/MyDrive/GPT4Mapping_test/output/Prompt_1.1*Sphinx.txt\")\n",
        "\n",
        "for document in os.listdir(\"/content/drive/MyDrive/GPT4Mapping_test/Prompt 1.1/\"):\n",
        "  if not any(str(Path(document).stem) in file for file in output_files):\n",
        "    retries = 0\n",
        "    while retries < max_retries:\n",
        "      try:\n",
        "        client = Client(\"http://llama-adapter.opengvlab.com/\")\n",
        "        result = client.predict(\n",
        "                \"https://drive.usercontent.google.com/download?id=\"+get_shareable_link(\"/content/drive/MyDrive/GPT4Mapping_test/Prompt 1.1/\"+document)+\"&export=view\",\t# str representing input in 'Input' Image component\n",
        "                \"List all map elements included in the given map.\",\t# str representing input in 'Prompt' Textbox component\n",
        "                500,\t# int | float representing input in 'Max length' Slider component\n",
        "                0.1,\t# int | float representing input in 'Temperature' Slider component\n",
        "                0.75,\t# int | float representing input in 'Top p' Slider component\n",
        "                fn_index=1\n",
        "        )\n",
        "        with open(\"/content/drive/MyDrive/GPT4Mapping_test/output/Prompt_1.1_\"+str(Path(document).stem)+\"_Sphinx.txt\", \"w\") as file:\n",
        "          file.write(result)\n",
        "        print(f\"Processed: {document}\")\n",
        "        time.sleep(3)\n",
        "        break  # Break out of the retry loop since processing was successful\n",
        "\n",
        "      except Exception as e:\n",
        "        retries += 1\n",
        "        print(f\"An error occurred while processing {document}: {e}\")\n",
        "        time.sleep(3)\n",
        "\n",
        "      if retries >= max_retries:\n",
        "                  print(f\"Failed to process {document} after {max_retries} retries.\")\n",
        "\n",
        "    time.sleep(3)\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "document"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "WE03EGU1-7W5",
        "outputId": "6399f0d5-1f60-4ee1-a535-da5c7bc4134c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'pop_batch_dot_05.jpeg'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 20
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from gradio_client import Client\n",
        "import os\n",
        "import time\n",
        "from pathlib import Path\n",
        "import glob\n",
        "max_retries = 2\n",
        "\n",
        "output_files = glob.glob(\"/content/drive/MyDrive/GPT4Mapping_test/output/Prompt_1.2_*Sphinx.txt\")\n",
        "\n",
        "for document in os.listdir(\"/content/drive/MyDrive/GPT4Mapping_test/Prompt 1.2/\"):\n",
        "  if not any(str(Path(document).stem) in file for file in output_files):\n",
        "    retries = 0\n",
        "    while retries < max_retries:\n",
        "      try:\n",
        "        client = Client(\"http://llama-adapter.opengvlab.com/\")\n",
        "        result = client.predict(\n",
        "                \"https://drive.usercontent.google.com/download?id=\"+get_shareable_link(\"/content/drive/MyDrive/GPT4Mapping_test/Prompt 1.2/\"+document)+\"&export=view\",\t# str representing input in 'Input' Image component\n",
        "                \"Identify the type of thematic map the given figure represents.\",\t# str representing input in 'Prompt' Textbox component\n",
        "                512,\t# int | float representing input in 'Max length' Slider component\n",
        "                0.1,\t# int | float representing input in 'Temperature' Slider component\n",
        "                0.75,\t# int | float representing input in 'Top p' Slider component\n",
        "                fn_index=1\n",
        "        )\n",
        "        with open(\"/content/drive/MyDrive/GPT4Mapping_test/output/Prompt_1.2_\"+str(Path(document).stem)+\"_Sphinx.txt\", \"w\") as file:\n",
        "          file.write(result)\n",
        "        print(f\"Processed: {document}\")\n",
        "        time.sleep(3)\n",
        "        break  # Break out of the retry loop since processing was successful\n",
        "\n",
        "      except Exception as e:\n",
        "        retries += 1\n",
        "        print(f\"An error occurred while processing {document}: {e}\")\n",
        "        time.sleep(3)\n",
        "\n",
        "      if retries >= max_retries:\n",
        "                  print(f\"Failed to process {document} after {max_retries} retries.\")\n",
        "\n",
        "    time.sleep(3)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8L_eH8S96QpG",
        "outputId": "79ea0fd8-5594-46b7-acd7-9fde2dd45764"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/huggingface_hub/utils/_token.py:88: UserWarning: \n",
            "The secret `HF_TOKEN` does not exist in your Colab secrets.\n",
            "To authenticate with the Hugging Face Hub, create a token in your settings tab (https://huggingface.co/settings/tokens), set it as secret in your Google Colab and restart your session.\n",
            "You will be able to reuse this secret in all of your notebooks.\n",
            "Please note that authentication is recommended but still optional to access public models or datasets.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Loaded as API: http://llama-adapter.opengvlab.com/ ✔\n",
            "Processed: pop_batch_gcmap_notitle_21.jpeg\n",
            "Loaded as API: http://llama-adapter.opengvlab.com/ ✔\n",
            "Processed: pop_batch_gcmap_notitle_20.jpeg\n",
            "Loaded as API: http://llama-adapter.opengvlab.com/ ✔\n",
            "Processed: pop_batch_gcmap_notitle_22.jpeg\n",
            "Loaded as API: http://llama-adapter.opengvlab.com/ ✔\n",
            "Processed: pop_batch_gcmap_notitle_29.jpeg\n",
            "Loaded as API: http://llama-adapter.opengvlab.com/ ✔\n",
            "Processed: pop_batch_gcmap_notitle_45.jpeg\n",
            "Loaded as API: http://llama-adapter.opengvlab.com/ ✔\n",
            "Processed: pop_batch_gcmap_notitle_51.jpeg\n",
            "Loaded as API: http://llama-adapter.opengvlab.com/ ✔\n",
            "Processed: pop_batch_dot_notitle_01.jpeg\n",
            "Loaded as API: http://llama-adapter.opengvlab.com/ ✔\n",
            "Processed: pop_batch_dot_notitle_05.jpeg\n",
            "Loaded as API: http://llama-adapter.opengvlab.com/ ✔\n",
            "Processed: pop_batch_dot_notitle_12.jpeg\n",
            "Loaded as API: http://llama-adapter.opengvlab.com/ ✔\n",
            "Processed: pop_batch_dot_notitle_13.jpeg\n",
            "Loaded as API: http://llama-adapter.opengvlab.com/ ✔\n",
            "Processed: pop_batch_dot_notitle_17.jpeg\n",
            "Loaded as API: http://llama-adapter.opengvlab.com/ ✔\n",
            "Processed: pop_batch_dot_notitle_18.jpeg\n",
            "Loaded as API: http://llama-adapter.opengvlab.com/ ✔\n",
            "Processed: pop_batch_dot_notitle_20.jpeg\n",
            "Loaded as API: http://llama-adapter.opengvlab.com/ ✔\n",
            "Processed: pop_batch_dot_notitle_21.jpeg\n",
            "Loaded as API: http://llama-adapter.opengvlab.com/ ✔\n",
            "Processed: pop_batch_dot_notitle_22.jpeg\n",
            "Loaded as API: http://llama-adapter.opengvlab.com/ ✔\n",
            "Processed: pop_batch_dot_notitle_24.jpeg\n",
            "Loaded as API: http://llama-adapter.opengvlab.com/ ✔\n",
            "Processed: pop_batch_dot_notitle_29.jpeg\n",
            "Loaded as API: http://llama-adapter.opengvlab.com/ ✔\n",
            "Processed: pop_batch_dot_notitle_28.jpeg\n",
            "Loaded as API: http://llama-adapter.opengvlab.com/ ✔\n",
            "Processed: pop_batch_dot_notitle_37.jpeg\n",
            "Loaded as API: http://llama-adapter.opengvlab.com/ ✔\n",
            "Processed: pop_batch_dot_notitle_39.jpeg\n",
            "Loaded as API: http://llama-adapter.opengvlab.com/ ✔\n",
            "Processed: pop_batch_dot_notitle_40.jpeg\n",
            "Loaded as API: http://llama-adapter.opengvlab.com/ ✔\n",
            "Processed: pop_batch_dot_notitle_45.jpeg\n",
            "Loaded as API: http://llama-adapter.opengvlab.com/ ✔\n",
            "Processed: pop_batch_dot_notitle_47.jpeg\n",
            "Loaded as API: http://llama-adapter.opengvlab.com/ ✔\n",
            "Processed: pop_batch_dot_notitle_48.jpeg\n",
            "Loaded as API: http://llama-adapter.opengvlab.com/ ✔\n",
            "Processed: pop_batch_dot_notitle_51.jpeg\n",
            "Loaded as API: http://llama-adapter.opengvlab.com/ ✔\n",
            "Processed: pop_batch_dot_notitle_54.jpeg\n",
            "Loaded as API: http://llama-adapter.opengvlab.com/ ✔\n",
            "Processed: pop_batch_psmap_notitle_01.jpeg\n",
            "Loaded as API: http://llama-adapter.opengvlab.com/ ✔\n",
            "Processed: pop_batch_psmap_notitle_05.jpeg\n",
            "Loaded as API: http://llama-adapter.opengvlab.com/ ✔\n",
            "Processed: pop_batch_psmap_notitle_12.jpeg\n",
            "Loaded as API: http://llama-adapter.opengvlab.com/ ✔\n",
            "Processed: pop_batch_psmap_notitle_13.jpeg\n",
            "Loaded as API: http://llama-adapter.opengvlab.com/ ✔\n",
            "Processed: pop_batch_psmap_notitle_18.jpeg\n",
            "Loaded as API: http://llama-adapter.opengvlab.com/ ✔\n",
            "Processed: pop_batch_psmap_notitle_20.jpeg\n",
            "Loaded as API: http://llama-adapter.opengvlab.com/ ✔\n",
            "Processed: pop_batch_psmap_notitle_21.jpeg\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from gradio_client import Client\n",
        "\n",
        "client = Client(\"http://llama-adapter.opengvlab.com/\")\n",
        "result = client.predict(\n",
        "\t\t\t\t\"https://raw.githubusercontent.com/gradio-app/gradio/main/test/test_files/bus.png\",\t# str representing input in 'Input' Image component\n",
        "\t\t\t\t\"Howdy!\",\t# str representing input in 'Prompt' Textbox component\n",
        "\t\t\t\t128,\t# int | float representing input in 'Max length' Slider component\n",
        "\t\t\t\t0,\t# int | float representing input in 'Temperature' Slider component\n",
        "\t\t\t\t0,\t# int | float representing input in 'Top p' Slider component\n",
        "\t\t\t\tfn_index=1\n",
        ")\n",
        "print(result)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dFG0w4D8wbms",
        "outputId": "c1be33da-da5e-4a46-e69c-c802720cad3a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Loaded as API: http://llama-adapter.opengvlab.com/ ✔\n",
            "I'm sorry, but I am an AI language model and I do not have the ability to browse images or see the image you are referring to. Can you please provide more information or context about the image you are referring to?\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from gradio_client import Client\n",
        "import os\n",
        "import time\n",
        "from pathlib import Path\n",
        "import glob\n",
        "max_retries = 2\n",
        "\n",
        "output_files = glob.glob(\"/content/drive/MyDrive/GPT4Mapping_test/output/Prompt_2.1_*Sphinx.txt\")\n",
        "\n",
        "for document in os.listdir(\"/content/drive/MyDrive/GPT4Mapping_test/Prompt 2.1/\"):\n",
        "  if not any(str(Path(document).stem) in file for file in output_files):\n",
        "    retries = 0\n",
        "    while retries < max_retries:\n",
        "      try:\n",
        "        client = Client(\"http://llama-adapter.opengvlab.com/\")\n",
        "        result = client.predict(\n",
        "                \"https://drive.usercontent.google.com/download?id=\"+get_shareable_link(\"/content/drive/MyDrive/GPT4Mapping_test/Prompt 2.1/\"+document)+\"&export=view\",\t# str representing input in 'Input' Image component\n",
        "                \"List the most likely point distribution (choose from random, dispersed, or clustered) in the attached figure.\",\t# str representing input in 'Prompt' Textbox component\n",
        "                512,\t# int | float representing input in 'Max length' Slider component\n",
        "                0.1,\t# int | float representing input in 'Temperature' Slider component\n",
        "                0.75,\t# int | float representing input in 'Top p' Slider component\n",
        "                fn_index=1\n",
        "        )\n",
        "        with open(\"/content/drive/MyDrive/GPT4Mapping_test/output/Prompt_2.1_\"+str(Path(document).stem)+\"_Sphinx.txt\", \"w\") as file:\n",
        "          file.write(result)\n",
        "        print(f\"Processed: {document}\")\n",
        "        time.sleep(3)\n",
        "        break  # Break out of the retry loop since processing was successful\n",
        "\n",
        "      except Exception as e:\n",
        "        retries += 1\n",
        "        print(f\"An error occurred while processing {document}: {e}\")\n",
        "        time.sleep(3)\n",
        "\n",
        "      if retries >= max_retries:\n",
        "                  print(f\"Failed to process {document} after {max_retries} retries.\")\n",
        "\n",
        "    time.sleep(3)\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "N4aXhyzmR03t",
        "outputId": "63b353ba-909a-4707-987a-e9706df040e0"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/huggingface_hub/utils/_token.py:88: UserWarning: \n",
            "The secret `HF_TOKEN` does not exist in your Colab secrets.\n",
            "To authenticate with the Hugging Face Hub, create a token in your settings tab (https://huggingface.co/settings/tokens), set it as secret in your Google Colab and restart your session.\n",
            "You will be able to reuse this secret in all of your notebooks.\n",
            "Please note that authentication is recommended but still optional to access public models or datasets.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Loaded as API: http://llama-adapter.opengvlab.com/ ✔\n",
            "Processed: pts_clustered_00.jpeg\n",
            "Loaded as API: http://llama-adapter.opengvlab.com/ ✔\n",
            "Processed: pts_clustered_01.jpeg\n",
            "Loaded as API: http://llama-adapter.opengvlab.com/ ✔\n",
            "Processed: pts_clustered_02.jpeg\n",
            "Loaded as API: http://llama-adapter.opengvlab.com/ ✔\n",
            "Processed: pts_clustered_03.jpeg\n",
            "Loaded as API: http://llama-adapter.opengvlab.com/ ✔\n",
            "Processed: pts_clustered_04.jpeg\n",
            "Loaded as API: http://llama-adapter.opengvlab.com/ ✔\n",
            "Processed: pts_clustered_05.jpeg\n",
            "Loaded as API: http://llama-adapter.opengvlab.com/ ✔\n",
            "Processed: pts_clustered_06.jpeg\n",
            "Loaded as API: http://llama-adapter.opengvlab.com/ ✔\n",
            "Processed: pts_clustered_07.jpeg\n",
            "Loaded as API: http://llama-adapter.opengvlab.com/ ✔\n",
            "Processed: pts_clustered_08.jpeg\n",
            "Loaded as API: http://llama-adapter.opengvlab.com/ ✔\n",
            "Processed: pts_clustered_09.jpeg\n",
            "Loaded as API: http://llama-adapter.opengvlab.com/ ✔\n",
            "Processed: pts_dispersed_00.jpeg\n",
            "Loaded as API: http://llama-adapter.opengvlab.com/ ✔\n",
            "Processed: pts_dispersed_01.jpeg\n",
            "Loaded as API: http://llama-adapter.opengvlab.com/ ✔\n",
            "Processed: pts_dispersed_02.jpeg\n",
            "Loaded as API: http://llama-adapter.opengvlab.com/ ✔\n",
            "Processed: pts_dispersed_03.jpeg\n",
            "Loaded as API: http://llama-adapter.opengvlab.com/ ✔\n",
            "Processed: pts_dispersed_04.jpeg\n",
            "Loaded as API: http://llama-adapter.opengvlab.com/ ✔\n",
            "Processed: pts_dispersed_05.jpeg\n",
            "Loaded as API: http://llama-adapter.opengvlab.com/ ✔\n",
            "Processed: pts_dispersed_06.jpeg\n",
            "Loaded as API: http://llama-adapter.opengvlab.com/ ✔\n",
            "Processed: pts_dispersed_07.jpeg\n",
            "Loaded as API: http://llama-adapter.opengvlab.com/ ✔\n",
            "Processed: pts_dispersed_08.jpeg\n",
            "Loaded as API: http://llama-adapter.opengvlab.com/ ✔\n",
            "Processed: pts_dispersed_09.jpeg\n",
            "Loaded as API: http://llama-adapter.opengvlab.com/ ✔\n",
            "Processed: pts_random_00.jpeg\n",
            "Loaded as API: http://llama-adapter.opengvlab.com/ ✔\n",
            "Processed: pts_random_01.jpeg\n",
            "Loaded as API: http://llama-adapter.opengvlab.com/ ✔\n",
            "Processed: pts_random_02.jpeg\n",
            "Loaded as API: http://llama-adapter.opengvlab.com/ ✔\n",
            "Processed: pts_random_03.jpeg\n",
            "Loaded as API: http://llama-adapter.opengvlab.com/ ✔\n",
            "Processed: pts_random_04.jpeg\n",
            "Loaded as API: http://llama-adapter.opengvlab.com/ ✔\n",
            "Processed: pts_random_05.jpeg\n",
            "Loaded as API: http://llama-adapter.opengvlab.com/ ✔\n",
            "Processed: pts_random_06.jpeg\n",
            "Loaded as API: http://llama-adapter.opengvlab.com/ ✔\n",
            "Processed: pts_random_07.jpeg\n",
            "Loaded as API: http://llama-adapter.opengvlab.com/ ✔\n",
            "Processed: pts_random_08.jpeg\n",
            "Loaded as API: http://llama-adapter.opengvlab.com/ ✔\n",
            "Processed: pts_random_09.jpeg\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from gradio_client import Client\n",
        "import os\n",
        "import time\n",
        "from pathlib import Path\n",
        "import glob\n",
        "max_retries = 2\n",
        "\n",
        "output_files = glob.glob(\"/content/drive/MyDrive/GPT4Mapping_test/output/Prompt_2.4_*Sphinx.txt\")\n",
        "\n",
        "for document in os.listdir(\"/content/drive/MyDrive/GPT4Mapping_test/Prompt 2.4/\"):\n",
        "  if not any(str(Path(document).stem) in file for file in output_files):\n",
        "    retries = 0\n",
        "    while retries < max_retries:\n",
        "      try:\n",
        "        client = Client(\"http://llama-adapter.opengvlab.com/\")\n",
        "        result = client.predict(\n",
        "                \"https://drive.usercontent.google.com/download?id=\"+get_shareable_link(\"/content/drive/MyDrive/GPT4Mapping_test/Prompt 2.4/\"+document)+\"&export=view\",\t# str representing input in 'Input' Image component\n",
        "                \"Describe the two tyeps of point distribution patterns (in green and blue) in the following map combined with the underlying income variable and tell which crime is more related to income?\",\t# str representing input in 'Prompt' Textbox component\n",
        "                512,\t# int | float representing input in 'Max length' Slider component\n",
        "                0.1,\t# int | float representing input in 'Temperature' Slider component\n",
        "                0.75,\t# int | float representing input in 'Top p' Slider component\n",
        "                fn_index=1\n",
        "        )\n",
        "        with open(\"/content/drive/MyDrive/GPT4Mapping_test/output/Prompt_2.4_\"+str(Path(document).stem)+\"_Sphinx.txt\", \"w\") as file:\n",
        "          file.write(result)\n",
        "        print(f\"Processed: {document}\")\n",
        "        time.sleep(3)\n",
        "        break  # Break out of the retry loop since processing was successful\n",
        "\n",
        "      except Exception as e:\n",
        "        retries += 1\n",
        "        print(f\"An error occurred while processing {document}: {e}\")\n",
        "        time.sleep(3)\n",
        "\n",
        "      if retries >= max_retries:\n",
        "                  print(f\"Failed to process {document} after {max_retries} retries.\")\n",
        "\n",
        "    time.sleep(3)\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZMDrwC_gBXOm",
        "outputId": "8838d0b8-ef60-4a79-9ac8-73972093b244"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/huggingface_hub/utils/_token.py:88: UserWarning: \n",
            "The secret `HF_TOKEN` does not exist in your Colab secrets.\n",
            "To authenticate with the Hugging Face Hub, create a token in your settings tab (https://huggingface.co/settings/tokens), set it as secret in your Google Colab and restart your session.\n",
            "You will be able to reuse this secret in all of your notebooks.\n",
            "Please note that authentication is recommended but still optional to access public models or datasets.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Loaded as API: http://llama-adapter.opengvlab.com/ ✔\n",
            "An error occurred while processing fig_as.jpg: no close frame received or sent\n",
            "Loaded as API: http://llama-adapter.opengvlab.com/ ✔\n",
            "An error occurred while processing fig_as.jpg: timed out\n",
            "Failed to process fig_as.jpg after 2 retries.\n",
            "Loaded as API: http://llama-adapter.opengvlab.com/ ✔\n",
            "An error occurred while processing fig_bg.jpg: no close frame received or sent\n",
            "Loaded as API: http://llama-adapter.opengvlab.com/ ✔\n",
            "An error occurred while processing fig_bg.jpg: no close frame received or sent\n",
            "Failed to process fig_bg.jpg after 2 retries.\n",
            "Loaded as API: http://llama-adapter.opengvlab.com/ ✔\n",
            "An error occurred while processing fig_cd.jpg: timed out\n",
            "Loaded as API: http://llama-adapter.opengvlab.com/ ✔\n",
            "An error occurred while processing fig_cd.jpg: no close frame received or sent\n",
            "Failed to process fig_cd.jpg after 2 retries.\n",
            "Loaded as API: http://llama-adapter.opengvlab.com/ ✔\n",
            "An error occurred while processing fig_mvt.jpg: timed out\n",
            "Loaded as API: http://llama-adapter.opengvlab.com/ ✔\n",
            "An error occurred while processing fig_mvt.jpg: no close frame received or sent\n",
            "Failed to process fig_mvt.jpg after 2 retries.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from gradio_client import Client\n",
        "import os\n",
        "import time\n",
        "from pathlib import Path\n",
        "import glob\n",
        "max_retries = 2\n",
        "\n",
        "\n",
        "try:\n",
        "  client = Client(\"http://llama-adapter.opengvlab.com/\")\n",
        "  result = client.predict(\n",
        "          \"https://drive.usercontent.google.com/download?id=\"+get_shareable_link(\"/content/drive/MyDrive/GPT4Mapping_test/Map Reading/map_test_1.1.png\")+\"&export=view\",\t# str representing input in 'Input' Image component\n",
        "          \"List all map elements included in the given map\",\t# str representing input in 'Prompt' Textbox component\n",
        "          512,\t# int | float representing input in 'Max length' Slider component\n",
        "          0.1,\t# int | float representing input in 'Temperature' Slider component\n",
        "          0.75,\t# int | float representing input in 'Top p' Slider component\n",
        "          fn_index=1\n",
        "  )\n",
        "  with open(\"/content/drive/MyDrive/GPT4Mapping_test/Prompt_1.1__Sphinx.txt\", \"w\") as file:\n",
        "    file.write(result)\n",
        "  print(f\"Processed: {document}\")\n",
        "  print(result)\n",
        "  time.sleep(3)\n",
        "\n",
        "except Exception as e:\n",
        "  retries += 1\n",
        "  print(f\"An error occurred while processing {document}: {e}\")\n",
        "  time.sleep(3)\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "s9DoBIGuC3V4",
        "outputId": "8425525a-e978-45d9-c97a-e45c60cb670f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Loaded as API: http://llama-adapter.opengvlab.com/ ✔\n",
            "Processed: fig_mvt.jpg\n",
            "The given map includes various elements such as a topographical map, a forest map, a state map, and a forest fire map.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from gradio_client import Client\n",
        "import os\n",
        "import time\n",
        "from pathlib import Path\n",
        "import glob\n",
        "max_retries = 2\n",
        "\n",
        "\n",
        "try:\n",
        "  client = Client(\"http://llama-adapter.opengvlab.com/\")\n",
        "  result = client.predict(\n",
        "          \"https://drive.usercontent.google.com/download?id=\"+get_shareable_link(\"/content/drive/MyDrive/GPT4Mapping_test/Map Reading/CV11_Fig1_1.jpg\")+\"&export=view\",\t# str representing input in 'Input' Image component\n",
        "          \"Vertical Axis and Horizontal Axis illustrates different types of map representation. List what types of thematic maps are in each quadrant of the figure attached.\",\t# str representing input in 'Prompt' Textbox component\n",
        "          512,\t# int | float representing input in 'Max length' Slider component\n",
        "          0.1,\t# int | float representing input in 'Temperature' Slider component\n",
        "          0.75,\t# int | float representing input in 'Top p' Slider component\n",
        "          fn_index=1\n",
        "  )\n",
        "  with open(\"/content/drive/MyDrive/GPT4Mapping_test/Prompt_1.2_Sphinx.txt\", \"w\") as file:\n",
        "    file.write(result)\n",
        "  print(f\"Processed: {document}\")\n",
        "  print(result)\n",
        "  time.sleep(3)\n",
        "\n",
        "except Exception as e:\n",
        "  retries += 1\n",
        "  print(f\"An error occurred while processing {document}: {e}\")\n",
        "  time.sleep(3)\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "X0cjjkiBScci",
        "outputId": "0c3577e3-211a-4004-9179-b2634b47a1eb"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Loaded as API: http://llama-adapter.opengvlab.com/ ✔\n",
            "Processed: fig_mvt.jpg\n",
            "The figure attached contains four quadrants, each representing a different type of thematic map. The first quadrant displays a vertical axis map, which is commonly used to represent data or information in a vertical direction, such as population density or elevation. The second quadrant contains a horizontal axis map, which is used to represent data or information in a horizontal direction, such as temperature or precipitation. The third quadrant features a vertical axis map with a horizontal axis, which combines both vertical and horizontal data representation. The fourth quadrant contains a horizontal axis map with a vertical axis, which also combines both vertical and horizontal data representation.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "8mcMSWeZSwiu"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}